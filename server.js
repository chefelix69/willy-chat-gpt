import express from 'express';
import { config } from 'dotenv';
import OpenAI from 'openai';
import cors from 'cors';
import fs from 'fs/promises'; // ×›×“×™ ×œ×§×¨×•× ××ª ×”Ö¾system prompt

config(); // ×˜×•×¢×Ÿ ××ª ×ž×¤×ª×— ×”Ö¾API ×ž×ª×•×š .env

const app = express();
const port = process.env.PORT || 3000;

app.use(cors()); // ×ž××¤×©×¨ ×¤× ×™×™×” ×ž×”×“×¤×“×¤×Ÿ
app.use(express.json());

// ×”×’×“×¨×ª OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ×¦'××˜ API
app.post('/chat', async (req, res) => {
  try {
    const userMessage = req.body.message;

    // ×§×¨×™××” ×œ×ª×•×›×Ÿ ×©×œ ×•×•×™×œ×™ ×ž×ª×•×š ×§×•×‘×¥
    const systemPrompt = await fs.readFile('./willy-systemPrompt.txt', 'utf-8');

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o', // ××¤×©×¨ ×’× gpt-3.5-turbo
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.9,
    });

    res.json({ response: completion.choices[0].message.content });
  } catch (error) {
    console.error('âŒ Error:', error);
    res.status(500).json({ error: 'Something went wrong.' });
  }
});

// ðŸŸ¢ ×ž×¡×œ×•×œ ×‘×¨×™×¨×ª ×ž×—×“×œ â€“ ×›×“×™ ×©Ö¾Render ×•Ö¾UptimeRobot ×™×§×‘×œ×• ×ª×©×•×‘×”
app.get('/', (req, res) => {
  res.send('âœ… Willy server is up and running!');
});

// ×ž××–×™×Ÿ ×œ×¤× ×™×•×ª
app.listen(port, () => {
  console.log(`âœ… Willy server is running on port ${port}`);
});
